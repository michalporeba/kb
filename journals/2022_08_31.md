- Watching [[Algorithms and Data Structures - Part 2]]
	- B-trees
		- B-tree is a sorted, balanced, tree structure, good for access to data on slow mediums.
		- While binary trees can have only one value per node and each node can have at most two child nodes. B-trees can have n values and n+1 child nodes.
		- Minimal Degree - minimal number of children
		- A leaf node to be valid has to have between n-1 and 2n-1
		- All leave nodes must be at the same hight
		- Search is O(log n)
		- Nodes are split before entering them for addition.
		- Root node is the only one that can have fewer values than the minimal degree.
		- The course has very useful animations showing addition, removal and balancing rotations.
		- `[Conditional("DEBUG")]` - an attribute in C# to allow conditional inclusion of a method.
	- Heaps
		- A heap is a tree-based container type that provides O(1) access to the minimum (min-heap) or maximum (max-heap) value while satisfying the heap property - the value in the current tree node is greater than, or equal to, its children (max-heap) or the reverse for the (min-heap).
		- Complete trees can be efficiently implemented using arrays allowing O(1) access to any node.
		- Priority queues are often implemented using heaps.
	- Concurrent collections
		- Using Monitor Lock - Caller Synchronisation
			- multithread operations on non-thread safe structures leads to undefined behaviour including data loss
			- simplest solution is caller synchronisation
			- When taking locks it is common practice to check first condition without the lock, to minimise synchronisation, and if the condition is potentially met then take the lock and check it again. It is often the cheaper option despite the duplication as taking locks is not free.
			- It's easy to implement, but easy to implement wrongly too. It is expensive as readers block readers. Non-concurrent-safe collections can be used in concurrent environments but the caller is responsible for thread synchronisation.
		- Collection Synchronisation
			- A single monitor lock can be used to serialize access to the container. The responsibility shifts but this is still readers block readers situation.
			- It is also possible to have separate reader/writer locking which allows concurrent reads with blocking writes.
			- Lock objects are class scoped.
			- Callers might need to be still aware of the concurrency and do some synchronisation.
		- Concurrent Collections
			- They are implemented in a concurrency safe, and often in non-locking manner.
- Watching [[Data Wrangling with Python 3]]
	- Data Wrangling - concatenating and merging data, normalising data and manipulating data in python. The course is aimed at aspiring ML, AI engineers and data scientists.
	- `frame = pd.DataFrame(data, column= ["colA", "colB"])`
	- `c = pd.concat([data1, data2])`
	- `data = pd.read_csv('filename')`, `data.head()`
	- `pd.append()` is deprecated and is equivalent to `pd.concat([...], axis=0, join='outer')`
	- `pd.merge` -> Merging can automatically merge when column names match
		- merging is joining two dataframes based on some common columns -> `pd.merge()`
		- `on` parameter allows to explicitly specify the name of the key column
		- `left_on` and `right_on` can be used instead when column names are different
		- `left_index` and `right_index` can be used to merge on position not name.
		- `how` parameter supports `inner`, `left`, `right`, `outer` values.
		- `indicator=True` adds a column indicating type of the match: `both`, `left_only`, `right_only`
	- `pd.groupby`
		- by default it returns data sorted. this can be surpassed by `sort=False` parameter
		- method returns grouping object
		- `groupped = data.groupby('colA')`, `groupped.sum()` displays sums.
		- `.mean()`, `.max()` are also available
	- Alternative is to use `agg` instead of `groupby`.
		- `results = groupped['colA'].agg({"colA": ['sum', 'max']})`
	- Normalisation
		- in this context, is changing values of features (columns) to make sure they are all on the same scale. This is down by scaling the values, typically into 0..1 range (simply feature scaling)
		- Min-Max Scaling is a bit more complex and ensures better use of the 0..1 range as min value is mapped to 0 and max to 1 while simple scaling maps absolute 0 to 0, so min value is somewhere between 0 and 1.
		- Z-Score - number of standard deviations from the mean of a given data point. It is also known as the standards score with values -3 to 3.
		- Normalisation is needed when data is to be used with models depending on distance calculations like [[KNN's]], [[Linear regression]] etc. Other models like [[Na√Øve Bayes]], [[Decision trees]] do not require data normalisation.
	-