- Watching [[Literacy Essentials: Core Concepts Convolutional Neural Network]]
	- [[Convolutional Neural Networks]] [[CNN]] gave computers 'human like' ability to understand pictures (have they really?)
	- CNNs are used for image processing, for example to help doctors in analysing scans
	- It is easier to analyse image if it is a single-channel and there is 1/3 or 1/4 of data of a typical multi-channel image. Looking independently on channels might be useful as different elements stand out.
	- Three levels of problems
		- Image classification - reducing an image to a single label - what class is present
		- Object detection - allows to identify multiple classes
		- Semantic and Instance Segmentation can split image or identify areas where a class is present.
	- AI and Deep Learning
		- [[Artificial Intelligence]] - general intelligent machine or programms
		- [[Machine Learning]] - programs that learn from data without explicit instructions
		- [[Deep Learning]] - a category of ML involving the use of Deep Neural Networks
		- [[Neural Network]] - a directional weighted graph containing interconnected nodes which attempt to learn the underlying relationships and patterns in data.
	- Neuron
		- `ActivationFunction((v1*w1 + v2*w2 + v3*w3) + bias)`
		- Activation functions determine if neuron fires or activates and can normalise output to a specified range.
		- Activation functions introduce _nonlinearity_ to the network and this is what allows the networks to learn, otherwise they would just pass things through.
		- Common activation functions
			- Sigmoid
			- Tanh
			- ReLU negative value mapped to zero and positives left alone
	- Training
		- Forward propagation -> comparison -> back propagation
		- underfitting - model doesn't work well after training
		- overfitting - model performs well on the training data, but poorly on the real data
		- balanced - what we want
	- Convolutions
		- simplified definition: a process in which a kernel is applied to an image in a sliding window pattern resulting in a feature map of the image
		- convolution layers extract features, starting from basic like edges, but to more complex items.
		- convolution layers are rotation invariant
		- Most common activation function for convolution layer is ReLU to make an image of the kernel's output.
		- Pooling operation typically takes the max value from the window. It is an example of a convolution layer that doesn't need training.
	- Famous CNNs for classification
		- LeNet by Yann LeCum - 1999 - one of the first
		- AlexNet by Alex Krizhevsky
		- VGGNet - Visual Geometry Group
		- GoogleLeNet
		- Resnet
	- Tools
		- Tensorflow - Google
		- Keras - now part of Tensorflow 2
		- PyTorch - Facebook
	-
	-